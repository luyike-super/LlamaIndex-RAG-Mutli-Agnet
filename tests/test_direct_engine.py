"""
ç›´æ¥æµ‹è¯•å¢å¼ºæŸ¥è¯¢å¼•æ“çš„èŠ‚ç‚¹è¿”å›åŠŸèƒ½
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.indices.index import load_nodes_from_disk
from src.query_engine.enhanced_query_engine import create_enhanced_query_engine
from src.utils.node_display import display_retrieved_nodes
from llama_index.core.indices import VectorStoreIndex

def test_enhanced_engine_directly():
    """ç›´æ¥æµ‹è¯•å¢å¼ºæŸ¥è¯¢å¼•æ“"""
    print("ğŸ”§ ç›´æ¥æµ‹è¯•å¢å¼ºæŸ¥è¯¢å¼•æ“")
    print("="*50)
    
    try:
        # 1. åŠ è½½æ–‡æ¡£èŠ‚ç‚¹
        print("ğŸ”„ åŠ è½½æ–‡æ¡£èŠ‚ç‚¹...")
        docs = load_nodes_from_disk()
        
        if not docs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£èŠ‚ç‚¹")
            return
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(docs)} ä¸ªæ–‡æ¡£èŠ‚ç‚¹")
        
        # 2. åˆ›å»ºå‘é‡ç´¢å¼•
        print("ğŸ”„ åˆ›å»ºå‘é‡ç´¢å¼•...")
        vector_index = VectorStoreIndex(docs)
        print("âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
        
        # 3. åˆ›å»ºå¢å¼ºæŸ¥è¯¢å¼•æ“
        print("ğŸ”„ åˆ›å»ºå¢å¼ºæŸ¥è¯¢å¼•æ“...")
        enhanced_engine = create_enhanced_query_engine(vector_index)
        print("âœ… å¢å¼ºæŸ¥è¯¢å¼•æ“åˆ›å»ºæˆåŠŸ")
        
        # 4. æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "HCSL",
            "ç¡¬ä»¶æ§åˆ¶",
            "è¾“å‡ºç±»å‹",
            "æ—¶é’Ÿé¢‘ç‡"
        ]
        
        for query in test_queries:
            print(f"\n{'='*60}")
            print(f"ğŸ” æŸ¥è¯¢: {query}")
            print('='*60)
            
            # æ–¹æ³•1: ä½¿ç”¨ä¸“ç”¨èŠ‚ç‚¹è·å–æ–¹æ³•
            print(f"\nğŸ“„ æ–¹æ³•1: ä½¿ç”¨ get_retrieved_nodes()")
            nodes = enhanced_engine.get_retrieved_nodes(query)
            
            if nodes:
                print(f"âœ… æ£€ç´¢åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹")
                display_retrieved_nodes(nodes, query, show_summary=True)
            else:
                print("âŒ æ²¡æœ‰æ£€ç´¢åˆ°ä»»ä½•èŠ‚ç‚¹")
            
            # æ–¹æ³•2: ä½¿ç”¨æ ‡å‡†æŸ¥è¯¢æ–¹æ³•
            print(f"\nğŸ“„ æ–¹æ³•2: ä½¿ç”¨æ ‡å‡† query() æ–¹æ³•")
            response = enhanced_engine.query(query)
            
            print(f"å“åº”ç±»å‹: {type(response)}")
            print(f"å“åº”å†…å®¹: {str(response)[:200]}...")
            
            if hasattr(response, 'source_nodes') and response.source_nodes:
                print(f"âœ… å“åº”åŒ…å« {len(response.source_nodes)} ä¸ªæºèŠ‚ç‚¹")
                
                # æ¯”è¾ƒä¸¤ç§æ–¹æ³•çš„ç»“æœ
                if nodes and response.source_nodes:
                    print(f"ğŸ” èŠ‚ç‚¹æ•°é‡å¯¹æ¯”:")
                    print(f"  get_retrieved_nodes(): {len(nodes)}")
                    print(f"  query().source_nodes: {len(response.source_nodes)}")
                    
                    # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦ç›¸åŒ
                    same_nodes = len(nodes) == len(response.source_nodes)
                    if same_nodes:
                        for i, (n1, n2) in enumerate(zip(nodes, response.source_nodes)):
                            if n1.node.get_content() != n2.node.get_content():
                                same_nodes = False
                                break
                    
                    print(f"  èŠ‚ç‚¹å†…å®¹æ˜¯å¦ç›¸åŒ: {'æ˜¯' if same_nodes else 'å¦'}")
            else:
                print("âš ï¸ å“åº”ä¸­æ²¡æœ‰æºèŠ‚ç‚¹")
    
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_node_metadata():
    """æµ‹è¯•èŠ‚ç‚¹å…ƒæ•°æ®æ˜¾ç¤º"""
    print("\nğŸ“Š æµ‹è¯•èŠ‚ç‚¹å…ƒæ•°æ®æ˜¾ç¤º")
    print("="*50)
    
    try:
        # åŠ è½½æ–‡æ¡£
        docs = load_nodes_from_disk()
        if not docs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£èŠ‚ç‚¹")
            return
        
        # åˆ›å»ºç´¢å¼•å’Œå¼•æ“
        vector_index = VectorStoreIndex(docs)
        enhanced_engine = create_enhanced_query_engine(vector_index)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        query = "HCSLç¡¬ä»¶æ§åˆ¶"
        nodes = enhanced_engine.get_retrieved_nodes(query)
        
        if nodes:
            print(f"âœ… æ£€ç´¢åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹")
            
            # æ˜¾ç¤ºè¯¦ç»†çš„èŠ‚ç‚¹ä¿¡æ¯
            for i, node_with_score in enumerate(nodes[:2], 1):
                node = node_with_score.node
                print(f"\nğŸ“‹ èŠ‚ç‚¹ {i} è¯¦ç»†ä¿¡æ¯:")
                print(f"  ğŸ¯ åˆ†æ•°: {node_with_score.score}")
                print(f"  ğŸ†” èŠ‚ç‚¹ID: {getattr(node, 'node_id', 'N/A')}")
                print(f"  ğŸ“š æ–‡æ¡£ID: {getattr(node, 'ref_doc_id', 'N/A')}")
                
                if hasattr(node, 'metadata') and node.metadata:
                    print(f"  ğŸ“Š å…ƒæ•°æ®:")
                    for key, value in node.metadata.items():
                        print(f"    â€¢ {key}: {str(value)[:100]}...")
                
                content = node.get_content()
                print(f"  ğŸ“ å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
                print(f"  ğŸ“ å†…å®¹é¢„è§ˆ: {content[:200]}...")
        else:
            print("âŒ æ²¡æœ‰æ£€ç´¢åˆ°èŠ‚ç‚¹")
    
    except Exception as e:
        print(f"âŒ å…ƒæ•°æ®æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_engine_directly()
    test_node_metadata() 