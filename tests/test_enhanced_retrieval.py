"""
å¢å¼ºæ£€ç´¢åŠŸèƒ½æµ‹è¯•
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.data_ingestion import run_ingestion_pipeline
from src.indices.index import build_tool_agents
from src.utils.retrieval_evaluator import RetrievalEvaluator, create_test_queries
from config.config_rag import RETRIEVAL_CONFIG

def test_enhanced_retrieval():
    """æµ‹è¯•å¢å¼ºæ£€ç´¢åŠŸèƒ½"""
    print("å¼€å§‹æµ‹è¯•å¢å¼ºæ£€ç´¢åŠŸèƒ½...")
    
    # 1. è·å–æ–‡æ¡£æŸ¥è¯¢å¼•æ“
    print("æ­£åœ¨åŠ è½½æ–‡æ¡£æŸ¥è¯¢å¼•æ“...")
    try:
        doc_engines = build_tool_agents()
        print(f"æˆåŠŸåŠ è½½ {len(doc_engines)} ä¸ªæ–‡æ¡£æŸ¥è¯¢å¼•æ“")
    except Exception as e:
        print(f"åŠ è½½æ–‡æ¡£æŸ¥è¯¢å¼•æ“å¤±è´¥: {e}")
        return
    
    if not doc_engines:
        print("æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢å¼•æ“ï¼Œæµ‹è¯•ç»ˆæ­¢")
        return
    
    # 2. åˆ›å»ºè¯„ä¼°å™¨
    evaluator = RetrievalEvaluator()
    
    # 3. åˆ›å»ºæµ‹è¯•æŸ¥è¯¢
    test_queries = create_test_queries()
    
    # 4. å¯¹æ¯ä¸ªæŸ¥è¯¢å¼•æ“è¿›è¡Œè¯„ä¼°
    all_results = {}
    
    for doc_id, engine in list(doc_engines.items())[:3]:  # åªæµ‹è¯•å‰3ä¸ªå¼•æ“
        print(f"\næ­£åœ¨æµ‹è¯•æ–‡æ¡£ {doc_id} çš„æŸ¥è¯¢å¼•æ“...")
        
        # è¿è¡Œè¯„ä¼°å¥—ä»¶
        evaluation_result = evaluator.run_evaluation_suite(
            test_queries=test_queries,
            query_engine=engine
        )
        
        all_results[doc_id] = evaluation_result
        
        # æ‰“å°è¯„ä¼°æŠ¥å‘Š
        print(f"\n=== æ–‡æ¡£ {doc_id} çš„è¯„ä¼°ç»“æœ ===")
        evaluator.print_evaluation_report(evaluation_result)
    
    # 5. æ‰“å°é…ç½®ä¿¡æ¯
    print("\n" + "="*50)
    print("å½“å‰æ£€ç´¢é…ç½®:")
    print("="*50)
    print(f"â€¢ ç›¸ä¼¼åº¦æ£€ç´¢æ•°é‡: {RETRIEVAL_CONFIG.get('similarity_top_k', 'N/A')}")
    print(f"â€¢ ç›¸ä¼¼åº¦é˜ˆå€¼: {RETRIEVAL_CONFIG.get('similarity_cutoff', 'N/A')}")
    print(f"â€¢ å¯ç”¨é‡æ’åº: {RETRIEVAL_CONFIG.get('enable_reranking', 'N/A')}")
    print(f"â€¢ é‡æ’åºä¿ç•™æ•°é‡: {RETRIEVAL_CONFIG.get('rerank_top_k', 'N/A')}")
    print(f"â€¢ å¯ç”¨æ··åˆæ£€ç´¢: {RETRIEVAL_CONFIG.get('enable_hybrid_search', 'N/A')}")
    
    # 6. æä¾›æ”¹è¿›å»ºè®®
    print("\n" + "="*50)
    print("æ£€ç´¢æ•ˆæœæ”¹è¿›å»ºè®®:")
    print("="*50)
    
    # åˆ†æç»¼åˆç»“æœ
    avg_scores = []
    avg_coverage = []
    avg_query_times = []
    
    for doc_id, result in all_results.items():
        if "summary" in result:
            summary = result["summary"]
            avg_scores.append(summary.get("avg_avg_score", 0))
            avg_coverage.append(summary.get("avg_keyword_coverage", 0))
            avg_query_times.append(summary.get("avg_query_time", 0))
    
    if avg_scores:
        overall_avg_score = sum(avg_scores) / len(avg_scores)
        overall_avg_coverage = sum(avg_coverage) / len(avg_coverage)
        overall_avg_time = sum(avg_query_times) / len(avg_query_times)
        
        print(f"\nğŸ“Š ç»¼åˆè¡¨ç°:")
        print(f"â€¢ å¹³å‡ç›¸ä¼¼åº¦åˆ†æ•°: {overall_avg_score:.3f}")
        print(f"â€¢ å¹³å‡å…³é”®è¯è¦†ç›–ç‡: {overall_avg_coverage*100:.1f}%")
        print(f"â€¢ å¹³å‡æŸ¥è¯¢æ—¶é—´: {overall_avg_time:.2f}ç§’")
        
        print(f"\nğŸ’¡ å»ºè®®:")
        
        if overall_avg_score < 0.7:
            print("â€¢ ç›¸ä¼¼åº¦åˆ†æ•°è¾ƒä½ï¼Œå»ºè®®:")
            print("  - è°ƒæ•´embeddingæ¨¡å‹å‚æ•°")
            print("  - ä¼˜åŒ–æ–‡æ¡£åˆ†å—ç­–ç•¥")
            print("  - å¢åŠ åŒä¹‰è¯æ‰©å±•")
        
        if overall_avg_coverage < 0.6:
            print("â€¢ å…³é”®è¯è¦†ç›–ç‡è¾ƒä½ï¼Œå»ºè®®:")
            print("  - å¯ç”¨æŸ¥è¯¢æ‰©å±•åŠŸèƒ½")
            print("  - ä¼˜åŒ–é‡æ’åºç®—æ³•")
            print("  - å¢åŠ æ£€ç´¢æ•°é‡(similarity_top_k)")
        
        if overall_avg_time > 2.0:
            print("â€¢ æŸ¥è¯¢æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®:")
            print("  - ä¼˜åŒ–ç´¢å¼•ç»“æ„")
            print("  - å‡å°‘åå¤„ç†æ­¥éª¤")
            print("  - ä½¿ç”¨æ›´å¿«çš„embeddingæ¨¡å‹")
        
        print(f"\nğŸ”§ æ¨èé…ç½®è°ƒæ•´:")
        
        if overall_avg_coverage < 0.5:
            print("â€¢ å¢åŠ similarity_top_kåˆ°15-20")
            print("â€¢ é™ä½similarity_cutoffåˆ°0.6")
            print("â€¢ å¢åŠ rerank_top_kåˆ°8-10")
        
        if overall_avg_score < 0.6:
            print("â€¢ è°ƒæ•´æ–‡æ¡£åˆ†å—å¤§å°:")
            print("  - Markdown: chunk_size=600, chunk_overlap=120")
            print("  - Word: chunk_size=1000, chunk_overlap=200")
            print("  - é»˜è®¤: chunk_size=800, chunk_overlap=160")

def test_single_query_detailed():
    """è¯¦ç»†æµ‹è¯•å•ä¸ªæŸ¥è¯¢"""
    print("\n" + "="*50)
    print("è¯¦ç»†å•æŸ¥è¯¢æµ‹è¯•")
    print("="*50)
    
    try:
        doc_engines = build_tool_agents()
        if not doc_engines:
            print("æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢å¼•æ“")
            return
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¼•æ“è¿›è¡Œè¯¦ç»†æµ‹è¯•
        first_engine = next(iter(doc_engines.values()))
        
        test_query = "ä½¿ç”¨ç¡¬ä»¶æ§åˆ¶æ¨¡å¼ï¼Œè¾“å‡ºç±»å‹è®¾ç½®ä¸º HCSL"
        
        print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
        
        # æ‰§è¡ŒæŸ¥è¯¢
        response = first_engine.query(test_query)
        
        print(f"\nå“åº”ç»“æœ:")
        print(f"å“åº”é•¿åº¦: {len(str(response))} å­—ç¬¦")
        print(f"å“åº”å†…å®¹: {str(response)[:500]}...")
        
        # åˆ†ææ£€ç´¢åˆ°çš„èŠ‚ç‚¹
        if hasattr(response, 'source_nodes') and response.source_nodes:
            print(f"\næ£€ç´¢åˆ°çš„èŠ‚ç‚¹æ•°é‡: {len(response.source_nodes)}")
            
            for i, node in enumerate(response.source_nodes[:3], 1):
                print(f"\nèŠ‚ç‚¹ {i}:")
                print(f"  ç›¸ä¼¼åº¦åˆ†æ•°: {node.score:.3f}")
                print(f"  å†…å®¹é•¿åº¦: {len(node.node.get_content())} å­—ç¬¦")
                print(f"  å†…å®¹é¢„è§ˆ: {node.node.get_content()[:200]}...")
        
    except Exception as e:
        print(f"è¯¦ç»†æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("å¯åŠ¨å¢å¼ºæ£€ç´¢åŠŸèƒ½æµ‹è¯•...")
    
    # è¿è¡Œä¸»è¦æµ‹è¯•
    test_enhanced_retrieval()
    
    # è¿è¡Œè¯¦ç»†æµ‹è¯•
    test_single_query_detailed()
    
    print("\næµ‹è¯•å®Œæˆï¼") 