"""
æµ‹è¯•æ–‡æ¡£èŠ‚ç‚¹æ£€ç´¢åŠŸèƒ½
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from src.indices.index import build_tool_agents
from src.utils.node_display import display_retrieved_nodes, save_nodes_to_json, NodeDisplayer
from src.query_engine.enhanced_query_engine import create_enhanced_query_engine
from llama_index.core.indices import VectorStoreIndex
from llama_index.core.schema import QueryBundle

def test_direct_node_retrieval():
    """æµ‹è¯•ç›´æ¥ä»å¢å¼ºæŸ¥è¯¢å¼•æ“è·å–èŠ‚ç‚¹"""
    print("ğŸ” æµ‹è¯•ç›´æ¥èŠ‚ç‚¹æ£€ç´¢åŠŸèƒ½...")
    
    try:
        # è·å–æ–‡æ¡£æŸ¥è¯¢å¼•æ“
        doc_engines = build_tool_agents()
        
        if not doc_engines:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢å¼•æ“")
            return
        
        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¼•æ“è¿›è¡Œæµ‹è¯•
        first_category = next(iter(doc_engines.keys()))
        first_engine = doc_engines[first_category]
        
        print(f"âœ… ä½¿ç”¨å¼•æ“: {first_category}")
        
        # æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ä½¿ç”¨ç¡¬ä»¶æ§åˆ¶æ¨¡å¼ï¼Œè¾“å‡ºç±»å‹è®¾ç½®ä¸º HCSL",
            "æ—¶é’Ÿè¾“å‡ºé¢‘ç‡é…ç½®",
            "èŠ¯ç‰‡ä¾›ç”µç”µå‹èŒƒå›´"
        ]
        
        for query in test_queries:
            print(f"\n{'='*60}")
            print(f"ğŸ” æŸ¥è¯¢: {query}")
            print('='*60)
            
            # æ–¹æ³•1ï¼šé€šè¿‡æ™®é€šæŸ¥è¯¢è·å–èŠ‚ç‚¹
            response = first_engine.query(query)
            
            if hasattr(response, 'source_nodes') and response.source_nodes:
                print(f"\nğŸ“„ æ–¹æ³•1ï¼šä»æŸ¥è¯¢å“åº”ä¸­è·å–èŠ‚ç‚¹")
                display_retrieved_nodes(
                    response.source_nodes, 
                    query=query, 
                    show_summary=True
                )
                
                # ä¿å­˜èŠ‚ç‚¹åˆ°JSONæ–‡ä»¶
                save_path = f"retrieved_nodes_{query[:10].replace(' ', '_')}.json"
                save_nodes_to_json(response.source_nodes, save_path)
            else:
                print("âŒ æŸ¥è¯¢å“åº”ä¸­æ²¡æœ‰source_nodes")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_enhanced_query_engine_nodes():
    """æµ‹è¯•å¢å¼ºæŸ¥è¯¢å¼•æ“çš„ä¸“ç”¨èŠ‚ç‚¹è·å–æ–¹æ³•"""
    print("\nğŸ”§ æµ‹è¯•å¢å¼ºæŸ¥è¯¢å¼•æ“çš„èŠ‚ç‚¹è·å–æ–¹æ³•...")
    
    try:
        # è¿™é‡Œæˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªå•ç‹¬çš„å¢å¼ºæŸ¥è¯¢å¼•æ“æ¥æµ‹è¯•
        # å…ˆè·å–æ–‡æ¡£
        from src.indices.index import load_nodes_from_disk
        from llama_index.core.indices import VectorStoreIndex
        
        docs = load_nodes_from_disk()
        if not docs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æ–‡æ¡£æ•°æ®")
            return
        
        # åˆ›å»ºå‘é‡ç´¢å¼•
        index = VectorStoreIndex(docs)
        
        # åˆ›å»ºå¢å¼ºæŸ¥è¯¢å¼•æ“
        enhanced_engine = create_enhanced_query_engine(index)
        
        # æµ‹è¯•ä¸“ç”¨èŠ‚ç‚¹è·å–æ–¹æ³•
        test_query = "HCSLè¾“å‡ºç±»å‹"
        print(f"\nğŸ” ä½¿ç”¨ä¸“ç”¨æ–¹æ³•æ£€ç´¢: {test_query}")
        
        # ä½¿ç”¨æ–°çš„get_retrieved_nodesæ–¹æ³•
        nodes = enhanced_engine.get_retrieved_nodes(test_query)
        
        if nodes:
            print(f"\nğŸ“„ æ–¹æ³•2ï¼šä¸“ç”¨èŠ‚ç‚¹è·å–æ–¹æ³•")
            display_retrieved_nodes(nodes, query=test_query, show_summary=True)
        else:
            print("âŒ æ²¡æœ‰æ£€ç´¢åˆ°èŠ‚ç‚¹")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_node_analysis():
    """æµ‹è¯•èŠ‚ç‚¹åˆ†æåŠŸèƒ½"""
    print("\nğŸ“Š æµ‹è¯•èŠ‚ç‚¹åˆ†æåŠŸèƒ½...")
    
    try:
        doc_engines = build_tool_agents()
        
        if not doc_engines:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢å¼•æ“")
            return
        
        first_engine = next(iter(doc_engines.values()))
        
        # æ‰§è¡ŒæŸ¥è¯¢
        response = first_engine.query("ç¡¬ä»¶æ§åˆ¶ HCSL è¾“å‡ºé…ç½®")
        
        if hasattr(response, 'source_nodes') and response.source_nodes:
            # åˆ›å»ºèŠ‚ç‚¹æ˜¾ç¤ºå™¨
            displayer = NodeDisplayer(max_content_length=300)
            
            # è·å–è¯¦ç»†ç»Ÿè®¡
            summary = displayer.get_nodes_summary(response.source_nodes)
            
            print("\nğŸ“Š è¯¦ç»†èŠ‚ç‚¹åˆ†æ:")
            print(f"âœ“ æ£€ç´¢åˆ°çš„èŠ‚ç‚¹æ•°é‡: {summary['total_nodes']}")
            print(f"âœ“ å¹³å‡ç›¸ä¼¼åº¦åˆ†æ•°: {summary['avg_score']:.4f}")
            print(f"âœ“ æœ€é«˜åˆ†æ•°: {summary['max_score']:.4f}")
            print(f"âœ“ æœ€ä½åˆ†æ•°: {summary['min_score']:.4f}")
            print(f"âœ“ æ€»å†…å®¹é•¿åº¦: {summary['total_content_length']} å­—ç¬¦")
            
            # æ˜¾ç¤ºåˆ†å¸ƒæƒ…å†µ
            if summary['doc_sources']:
                print(f"\nğŸ“š æ–‡æ¡£æ¥æºåˆ†æ:")
                for doc, count in summary['doc_sources'].items():
                    print(f"  â€¢ {doc}: {count} ä¸ªèŠ‚ç‚¹")
            
            if summary['categories']:
                print(f"\nğŸ·ï¸ ç±»åˆ«åˆ†æ:")
                for category, count in summary['categories'].items():
                    print(f"  â€¢ {category}: {count} ä¸ªèŠ‚ç‚¹")
            
            # æ˜¾ç¤ºå‰3ä¸ªæœ€ç›¸å…³çš„èŠ‚ç‚¹
            print(f"\nğŸ† Top 3 æœ€ç›¸å…³èŠ‚ç‚¹:")
            sorted_nodes = sorted(
                response.source_nodes, 
                key=lambda x: x.score or 0, 
                reverse=True
            )
            
            for i, node in enumerate(sorted_nodes[:3], 1):
                content_preview = node.node.get_content()[:100] + "..."
                print(f"  {i}. åˆ†æ•°: {node.score:.4f} | å†…å®¹: {content_preview}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_custom_node_filter():
    """æµ‹è¯•è‡ªå®šä¹‰èŠ‚ç‚¹è¿‡æ»¤"""
    print("\nğŸ”§ æµ‹è¯•è‡ªå®šä¹‰èŠ‚ç‚¹è¿‡æ»¤...")
    
    try:
        doc_engines = build_tool_agents()
        
        if not doc_engines:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„æŸ¥è¯¢å¼•æ“")
            return
        
        first_engine = next(iter(doc_engines.values()))
        
        # æ‰§è¡ŒæŸ¥è¯¢
        response = first_engine.query("æ—¶é’Ÿ é¢‘ç‡ é…ç½®")
        
        if hasattr(response, 'source_nodes') and response.source_nodes:
            all_nodes = response.source_nodes
            
            print(f"ğŸ“„ åŸå§‹èŠ‚ç‚¹æ•°é‡: {len(all_nodes)}")
            
            # è‡ªå®šä¹‰è¿‡æ»¤ï¼šåªä¿ç•™åˆ†æ•°å¤§äº0.3çš„èŠ‚ç‚¹
            high_score_nodes = [
                node for node in all_nodes 
                if node.score and node.score > 0.3
            ]
            
            print(f"ğŸ¯ é«˜åˆ†èŠ‚ç‚¹ (>0.3): {len(high_score_nodes)}")
            
            # è‡ªå®šä¹‰è¿‡æ»¤ï¼šåªä¿ç•™åŒ…å«ç‰¹å®šå…³é”®è¯çš„èŠ‚ç‚¹
            keyword_nodes = [
                node for node in all_nodes
                if any(keyword in node.node.get_content().lower() 
                      for keyword in ['æ—¶é’Ÿ', 'clock', 'é¢‘ç‡', 'frequency'])
            ]
            
            print(f"ğŸ” å…³é”®è¯åŒ¹é…èŠ‚ç‚¹: {len(keyword_nodes)}")
            
            # æ˜¾ç¤ºè¿‡æ»¤åçš„èŠ‚ç‚¹
            if high_score_nodes:
                print(f"\nğŸ“‹ é«˜åˆ†èŠ‚ç‚¹è¯¦æƒ…:")
                display_retrieved_nodes(high_score_nodes, show_summary=False)
        
    except Exception as e:
        print(f"âŒ è¿‡æ»¤æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•æ–‡æ¡£èŠ‚ç‚¹æ£€ç´¢åŠŸèƒ½")
    print("="*60)
    
    # æµ‹è¯•1ï¼šç›´æ¥èŠ‚ç‚¹æ£€ç´¢
    test_direct_node_retrieval()
    
    # æµ‹è¯•2ï¼šå¢å¼ºæŸ¥è¯¢å¼•æ“ä¸“ç”¨æ–¹æ³•
    test_enhanced_query_engine_nodes()
    
    # æµ‹è¯•3ï¼šèŠ‚ç‚¹åˆ†æ
    test_node_analysis()
    
    # æµ‹è¯•4ï¼šè‡ªå®šä¹‰è¿‡æ»¤
    test_custom_node_filter()
    
    print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼") 